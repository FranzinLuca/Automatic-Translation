{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b5cf26",
   "metadata": {},
   "source": [
    "## Deepseek R1 qwen3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2b818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137fd436",
   "metadata": {},
   "source": [
    "the model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695c0981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='yarn': {'attn_factor'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 4096, padding_idx=151654)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"unsloth/DeepSeek-R1-0528-Qwen3-8B-bnb-4bit\"\n",
    "device = \"cuda\" \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d45ea",
   "metadata": {},
   "source": [
    "an example of one translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7efd7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marco Cornelio, uno dei dieci compagni, si riservò attentamente di parlare solo all'ultimo.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Marco Cornelio ch'era de' dieci compagni, studiosamente  si riservò di parlare all'ultimo.\"\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"you are a translator from old italian to model italian. you take a sentence in old italian and you answer only with: La traduzione è:<translation> . Don't add anything else. Translate only in italian\"},\n",
    "        {\"role\": \"system\", \"content\": \"only use italian and no other language in the translation\"},\n",
    "        {\"role\": \"user\", \"content\": prompt} \n",
    "    ]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=5000,\n",
    "    do_sample=True, \n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "\n",
    "new_tokens = generated_ids[0][len(model_inputs[0]):]\n",
    "decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "decoded = decoded.split(\"La traduzione è:\")[-1].strip()\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603e08",
   "metadata": {},
   "source": [
    "the code to translate all the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221cf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In quale battaglia, certamente io avevo sempre il coraggio di discutere di pace e mi sembrava che non soltanto la pace fosse disprezzata.\n",
      "L'abitudine seconda spesso può essere spaventosa a causa della sua grande provvidenza, e l'abitudine prima può essere audace al punto di far impazzire.\n",
      "Andò nel campo degli Cartaginesi e tutta la legione lo seguì in silenzio.\n",
      "Non lo volle riconoscere come nemico. Questa è quella che diede coraggio al profeta Nathan per riprendere con grande autorità quel re, che aveva peccato.\n",
      "Le armi e insieme con loro passarono tra i nemici, quindi se nessuno non avesse avuto il coraggio di questo, e quindi avevano quell'atteggiamento.\n",
      "Perché ragionevolmente si interpreta Iob come afflitto;\n",
      "Chi, tra tutti, perdonasse di più ai cittadini, e a cui foste più sicuri di credere, poi che egli era vostro comandante.\n",
      "Chi ha scritto questo libro deve essere creduto fedelmente lo Spirito Santo, e chiedersi chi l'abbia scritto è inutile.\n",
      "se non fosse così usata, ciò apparirebbe certamente molto più incredibile; anzi, più agevolmente si potrebbe credere in quello, supposto che l'animo umano sia divino e il mutabile sia immutabile.\n",
      "Che prendessero il compenso dal camerlingo per il loro mantenimento e per le provviste, e poi andassero alla presenza del Papa per contraddire il movimento dei cavalieri che si avvicinino da Cecilia in Toscana.\n",
      "Teseo guardò Achelao con grande meraviglia e disse: \"O Signore Achelao, ti prego, dimmi in che modo hai perso\".\n",
      "Spero che il Signore Gesù spedisca Timothy presto, affinché io sia di buon umore.\n",
      "Il maiale selvatico procede senza fallo, l'uomo dell'udito e il cinghiale del vedere.\n",
      "Un luogo si allevano capre; la quale cosa i cavalieri la chiamano capro.\n",
      "Tendi le lenze ai cervi e conosce bene in quali valli abiti il cinghiale furioso.\n",
      "Ora spaventerai i cervi speranzosi con varie paure, o il maiale ti mangia il coltello caduto a terra.\n",
      "tratta la natura delle cose incorporee, le quali non conversano tra i corpi, sì come Dio e le divine cose.\n",
      "Dio, per il quale si dispensano e si giudicano tutte le cose.\n",
      "Quindi i poeti, parlando di loro, dicono le loro virtù e li dicono i difetti in modo esagerato, quando nessuno era loro deputato.\n",
      "e quella cosa, la quale è diritta e onesta, e con virtù, solo penso essere il bene.\n",
      "Quando i serpenti attaccavano di giorno alcuni Romani, allora era la maraviglia vedere come i Psille si combattevano al veleno, perché essi immolavano tutta la loro saliva in avanti.\n",
      "Dice il poeta: oh, che bella cosa è vedere apertamente con gli occhi la cui chiarezza apporti, o in retroguardia, o d'altre parti.\n",
      "Ma pure questo era colpa tua, eppure hai voluto cercare di vedere con gli occhi del corpo la cosa invisibile.\n",
      "È vero, ma non ti rispondo in questo tempo, perciò che tu sei mio servo, o perché è tempo feriado, o perché io non devo risponderti.\n",
      "Si conviene che a loro si desse grande fortuna perché potessero andarsene via.\n",
      "Un esempio notevole ammonì ciascuno a non tradire la fiducia, e il servo, il quale l'aveva tradita, fu punito e gli furono donate grandi somme di denaro.\n",
      "Se l'avessero commesso sì che la colpa del servo e il suo gastigamento avessero meritato allo stesso modo il castigo di Platone.\n",
      "Dio mostrò massimamente le sue forze, assegnando il regno di questa città a un servo; e a quel re avvenne lunghissimamente reggere l'impero.\n",
      "L'anima cambia la sua forza per la proprietà di quel corpo a cui si congiunge.\n",
      "Sono due cose già non in un corpo, ma in uno spirito, cioè in Dio e nell'anima. E infatti, S. Paolo in un altro luogo afferma: Chi si avvicina a Dio è uno spirito.\n",
      "Dato ciò, Lucano disse a voi. Lì, quando l'anima di Pompeo ebbe sentito la chiarezza del lusso, essa conobbe prima in modo molto grande.\n",
      "Quando il dolore si percepisce all'udito, quando l'uso dell'arma e la fatica sono rifiutati, si prova grande imbarazzo, agendo come delle pecore.\n",
      "E non che Cristo ne avesse fastidio per tali parole.\n",
      "La moltitudine di cui hai potuto vedere lo studio e poco prima udire le voci, e le cui mani e lance appena posso afferrare.\n",
      "Udire di belle notizie e odorare di bei fiori, come, quando e quanto si conviene.\n",
      "Il re entrò in un giardino dietro al suo albergo, quasi come se stava pensando alla risposta.\n",
      "Ma io desidero dove io non posso col corpo andare, solo con la mente vorrei.\n",
      "Ecco che di subito tutta questa turba degli uccelli si levò a volo dietro all'aquila.\n",
      "Vede anche le ragioni del volo degli uccelli e di tutte le cose sa dare un giudizio corretto.\n",
      "Ecco, per il suo superbo orgoglio, questo uccello volava in alto.\n",
      "Gorgone, e ho questa proprietà che io volo nell'aria sì come un uccellino.\n",
      "Quando nel diploma si scrive un giuramento, si giura in nome di Dio, di Cristo e dello Spirito Santo.\n",
      "per necessità io dico che, secondo il tuo comandamento, Signore Santo Agostino, le battaglie già combattute nel mondo\n",
      "Il nome reale sarà sempre santo e glorioso nella nostra città, e il nome dei suoi compagni sarà santissimo.\n",
      "Non voglio che tu sia superbo per il tuo santo proposito, e che io faccio un voto di verginità vedendo le sue lodi.\n",
      "San Agostino fece un libro ch'avea nome \"Agostino Della Città di Dio\".\n",
      "Gregorio. Mai udii che avesse maestro; ma il dono dello Spirito Santo non può esser legato a leggi.\n",
      "E cioè, i mercatanti fiorentini viaggiavano in nave per andare oltramare.\n",
      "Quando avrai un cavaliere con quei segni, non abbandonarti alla sua grandezza cadendo, perché i forti sono più utili dei grandi.\n",
      "e il suo comune lasciare che vinca.\n",
      "Sapete che se non avessimo fuggito in fretta, saremmo morti tutti.\n",
      "Tarco, sebbene potesse fuggire in aiuto dei suoi nemici, non potè abbandonare gli Achei, i cavalieri nobilissimi che si trovavano poco avanti a lui.\n",
      "e l'accorgersi di fare grandi cose, cioè mantenere la pace e amare Dio e il prossimo, costruire città, castelli e palazzi\n",
      "Chi ancora non sa amare il prossimo come sé stesso già comincia a temere i giudizi di Dio.\n",
      "L'uccello, dopo che ha impennato le ali, non fugge liberamente, né il cervo selvatico esce facilmente dalle reti dove cade.\n",
      "\"Io lo aprii, e quelli fuggirono. E che bisogno c'è, che il tuo cuore sia chiuso al tuo sposo Cristo?\"\n",
      "Ecco, poiché queste cose sono così, Catellina, e tu non puoi dimorare qui con comodità, dubiti tu di andare in nessuna terra e usare questa vita fuggendo nei deserti?\n",
      "Questi due, volevano rimanere nella carica di tribuno nonostante la volontà del senato, furono assassinati dalla plebe, che fu incitata dai consoli.\n",
      "I giovani, che sono stati affidati il difeso delle province e la sorte di tutta la battaglia.\n",
      "Gli esploratori dei Monti della Romagna furono fatti nuovi nemici; contro i quali fu combattuto con diverse sorti: perché nella prima battaglia, quando Valerio era console, 3000 degli Romani persi morirono.\n",
      "Noi colpevoli e divisi per il debito della città, e tutti i colpevoli a causa della fama e della buona fortuna.\n",
      "Avete pregato i vostri dei per me; e i vostri preghi hanno avuto successo: e se domandate chi ha avuto la vittoria in questa battaglia, io non sono stato sconfitto da lui.\n",
      "Una villa si chiama Vitermina. Con ciò che più sorti i principi di scherani corressero per caso in quel tempo per vederlo, Scipione credeva che fossero venuti per attaccarlo, e quindi si è nascosto in casa.\n",
      "Contro di lui, contro le sue sorelle, contro il regno, e contro il prestigio della sua nascita e della sua famiglia.\n",
      "Quindi la nave fu ormeggiata e messa in mare aperto per affrontare direttamente questo periglioso transito, e l'aria divenne nuvolosa e piovigginosa.\n",
      "Salirono sul bordo del fosso e poi oltre il confine, se potessero difendersi dall'alto, oppure se avessero un mezzo per superarlo e salvarsi.\n",
      "Ma l'occhio dell'intelligenza è più elevato. Perciò, superata la grandezza dell'università, quella medesima semplice forma percepisce in una visione sottile.\n",
      "E se l'occhio è un membro nobile del corpo dell'uomo, dunque la salutazione è una parte nobile della pistola, c'è altresì qualcosa che illumina tutta la lettera come l'occhio illumina l'uomo.\n",
      "I Tarentini, i quali erano nati da quegli Sparti di Lacedemonia e fatti nobili dalla loro nobile cittade greca.\n",
      "L'uomo Ulecois era un uomo ricco e nobile: fu chiamato per nome da Orgentore.\n",
      "Tuttavia, se attaccare il nemico è un'azione nobile e importante, allora non è meno meritevole sapere come esercitare misericordia.\n",
      "Alessandro, il figlio e il genero, provenienti da Phausonia, giovani di Macedonia, trovandosi in un luogo angusto e senza guardia, morirono.\n",
      "C'è una persona che è ricca e gentile, ma si lamenta che vorrebbe avere un'altra moglie, diversa da quella che ha.\n",
      "Pietro, mostratigli in visione il popolo dei Gentili, pertanto fu detto a Pietro: uccidi e mangia.\n",
      "Pregai che lo liberasse da quella obbligazione, in quella che egli l'aveva redatta obbligandolo. Il gentile uomo acconsentì, e lo liberò, e ne fece un documento.\n",
      "L'oro arriverà dal Nord-Ovest. Se non siamo il popolo dei Gentili gelati dal freddo del peccato, in cosa rappresentiamo noi per il Nord-Ovest? Un popolo che ci ha sottomessi sotto il giogo della sua tirannia.\n",
      "Sia tu tra me e te: con noi non puoi già dimorare più a lungo, e io non la sopporterò e non lo lascherò\".\n",
      "\n",
      "Ma \"già\" è \"already\", e in italiano moderno, \"non puoi già\" non è corretto.\n",
      "\n",
      "\"Non puoi (già) dimorare\" più, ma \"già\" va prima.\n",
      "\n",
      "Forse è \"con noi non potete già dimorare\" più, ma è \"tu\".\n",
      "\n",
      "\"Tu\" è \"you\", quindi \"non puoi\".\n",
      "\n",
      "E \"già\".\n",
      "\n",
      "In italiano moderno, \"non puoi già\" non è usato; \"già\" è con \"posso\" o \"possono\".\n",
      "\n",
      "\"Non puoi\" + \"già\" + \"dimorare\".\n",
      "\n",
      "Forse è \"non puoi già\" come \"non puoi (già) farlo\", ma \"già\" è avverbio.\n",
      "\n",
      "\"Non puoi già dimorare\" – \"already you can't stay\", che è strano.\n",
      "\n",
      "\"Non puoi (già) dimorare\" – \"you can't stay already\", che è \"you can't stay anymore\".\n",
      "\n",
      "\"Dimorare\" è \"stay\",\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('dataset_cleaned.csv')\n",
    "\n",
    "# Create new column for translations\n",
    "df['Deepseek R1 qwen-8b'] = ''\n",
    "\n",
    "# Process each row\n",
    "for idx, row in df.iterrows():\n",
    "    # Create messages with current prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"you are a translator from old italian to model italian. you take a sentence in old italian and you answer only with: La traduzione è:<translation> . Don't add anything else. Translate only in italian\"},\n",
    "        {\"role\": \"system\", \"content\": \"only use italian and no other language in the translation\"},\n",
    "        {\"role\": \"user\", \"content\": row['Sentence']} \n",
    "    ]\n",
    "    \n",
    "    # Prepare input\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate translation\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=10000,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    # Decode and clean up response\n",
    "    new_tokens = generated_ids[0][len(model_inputs[0]):]\n",
    "    decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    translation = decoded.split(\"La traduzione è:\")[-1].strip()    \n",
    "    print(translation)\n",
    "    \n",
    "    # Store translation\n",
    "    df.at[idx, 'Deepseek R1 qwen-8b'] = translation\n",
    "\n",
    "# Save updated dataframe to dataset_deepseek.csv\n",
    "df.to_csv('./dataset/dataset_deepseek.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6675dd",
   "metadata": {},
   "source": [
    "cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724449d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the vram memory\n",
    "torch.cuda.empty_cache()\n",
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7705f8",
   "metadata": {},
   "source": [
    "## Mistral Mistral-7B-Instruct-v0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd9daad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1200df22",
   "metadata": {},
   "source": [
    "the model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be3a051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:39<00:00, 13.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" \n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a026674",
   "metadata": {},
   "source": [
    "one translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91108ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La traduzione è: \"La folla di coloro che hai potuto vedere e guardare lo studio e di quelli che stavano poco lontano e udire le voci, e le mani e le armi di pochi che posso ancora ricordare.\" (Traduction: \"The crowd of those whom you have been able to see and observe in the study, and of those who were just a little away and hear the voices, and the hands and weapons of a few that I can still remember.\")\n"
     ]
    }
   ],
   "source": [
    "prompt = \"la moltitudine de' quali tu ài potuto vedere e riguardare lo studio e poco dinanzi udire le voci, e lle cui mani e lance apena posso ritenere.\"\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Sei un traduttore dall'italiano antico all'italiano moderno. Traduci una frase in italiano moderno e rispondi solo con: La traduzione è:<traduzione>. Non aggiungere altro pena la morte. Usa solo l'italiano e nessun'altra lingua nella traduzione.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt} \n",
    "    ]\n",
    "\n",
    "tokens = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "attention_mask = torch.ones_like(tokens)\n",
    "\n",
    "# Move to device\n",
    "model_inputs1 = tokens.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "\n",
    "# Generate with attention mask\n",
    "generated_ids1 = model.generate(\n",
    "    model_inputs1, \n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=1000, \n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Decode only the new tokens (exclude the input)\n",
    "new_tokens = generated_ids1[0][len(tokens[0]):]\n",
    "decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd11146",
   "metadata": {},
   "source": [
    "code for all database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbd35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quella guerra fu bene condotta, ma da una parte, Aiace era un cavaliere francese e valente in battaglia, ma non era molto sagace.\n",
      "\"Crudele, e di tutte le colpe prende vendetta, come dice la legge, e a nessun cavaliere perdonerai peccati.\"\n",
      "\"Ponzio Aufidiano, cavaliere romano, non fu arricchito di altra forza d'animo.\"\n",
      "Se questo piace a tutti e se il tempo ha bisogno di avere Pompeio come cavaliere e non come compagno, io non lo riterrò ancora come destinato.\n",
      "Sembra che questa arte faccia dire appositamente per far credere, il fine è far credere per quanto si dice.\n",
      "\"Quarantaquattro grandi ventagli cadono delle nebbie decisive; e potresti credere che tutto il cielo cadesse nel mare.\"\n",
      "\"Ma chi potrebbe sperare di quello che ancora questi non credono in Cristo, lo possono vedere con noi, e perché non possono negare, lo fanno con denti e grida.\"\n",
      "Le vendite dei morti e le pressioni dei vivi fecero il tranello di un re ferocio.\n",
      "Affinché quelli, il quale ora per le sue grandi reati è ferocissimo e onoroso, egli, da ogni male afflitto e tormentato, mostra impietas verso mio padre.\n",
      "Gli uomini, soprattutto, restano fermi nella menzogna incontrano la verità.\n",
      "Marco Cornelio, tra i dieci compagni, si riservò di parlarlo all'ultimo.\n",
      "le cose che io conoscevo essere fatte in Italia.\n",
      "Corbio, figlio di Ortensio, condusse una vita più bassa e più viziosa.\n",
      "Un amante chiamandola merzé alla sua donna dice parole e ragioni molte, e lei si difende con sue parole.\n",
      "Io ricordo che, essendo infuriato, scoprì la mia donna. Oh, quanti giorni questa rabbia mi tolse!\n",
      "l'uomo del cui amore tu ti ricordavi di aver sofferto per la tua donna;\n",
      "Ma non sapevano ancora i nomi di coloro della congiura, poiché la donna non nominava ancora i loro nomi.\n",
      "\"Creti? Sicuramente lo fece dire a te: 'O mia fedele donna, rimedi per me presso nostro ospite troiano'.\"\n",
      "A Milano fu repressa la malvagità di una donna in modo simile a questa signora della repubblica:\n",
      "Essi lamentavansi dell'ingiustizia di Appio, e ripianevano la misera bellezza della giovane e la necessità del padre.\n",
      "In quale battaglia, certamente io ho sempre avuto coraggio di ragionare di pace e sempre mi dispiace che non solo la pace era offesa,\n",
      "la seconda può talvolta far paura per il grande vantaggio, e la prima può rendere chiaro il follia di altri.\n",
      "Andai nel campo dei Cartaginesi e la legione intera lo seguì.\n",
      "Quella lo volle ignota al profeta Natan, per cui ebbe il coraggio di riprovare con grande autorità quel re peccatore.\n",
      "Con le armi e insieme passano tra i nemici, per cui, se qualcuno non avesse il coraggio di questo e avessero questo animo.\n",
      "Per ragioni ragionevoli, Iobe è stato interpretato come dolente.\n",
      "\"Quello che perdonava ai cittadini sopra a tutti gli altri, e a cui potete più sicuramente credere, era il vostro comandante.\"\n",
      "Inutile chiedersi chi scrivesse questo Libro, in quanto fedelmente si deve credere che l'Autore fosse lo Spirito Santo.\n",
      "Se non fosse comunissimo, certamente apparirebbe molto più incredibile: sicuramente si può più facilmente credere quello, poiché l'umano spirito al divino, e il mutabile all'incommutabile.\n",
      "Quelli ricevevano il loro stipendio dal camerlengo per il loro turno e andavano subito alla presenza di monsignor il papa per contrarre i cavaliere che venivano da Cecilia in Toscana.\n",
      "\"O signor Acheloo, io ti prego di dirti come vi siete perditi.\"\n",
      "Io spero che Gesù mi permetta di inviare presto a voi Timoteo, affinché io sia tranquillo inside<traduzione>.\n",
      "senza errori, il selvaggio maiale avanza, l'uomo di ascoltare e il lupo cervo del vedere.\n",
      "In quel luogo si gettano lanci, e ciò è chiamato \"capo di maiale\" dai cavalieri.\n",
      "\"Tenda le reti agli scorcianni e sa bene in quale valle abita il furioso maiale selvaggio.\"\n",
      "Avrete paura di spaventare i cervi timidi con diverse paure, o il maiale inseguirà il passato collo nel terreno impalato.\n",
      "tratta le cose incorporee, come Dio e le cose divine, che non si convertiscono tra i corpi.\n",
      "Dio, per cui si dispensano e giudicano tutte le cose.\n",
      "\"Gli poeti, parlando di loro, dichiarano le loro virtù e fabbricano allusivamente i loro difetti, quando una passava in ordine a loro deputato.\"\n",
      "Quella cosa, la quale è diretta, onesta e virtuosa, è la unica cosa che penso essere buona.\n",
      "Quando serpenti gli schioccavano le loro veleno delle giornate, meravigliosi erano i Romani di vedere come i Psille si combattevano al veleno, poiché essi sacrificavano tutto in pratica della loro saliva.\n",
      "Oh, quanto è bella cosa vedere apertamente con gli occhi quando tu la fai direttamente in faccia o dietro o in alto.\n",
      "Purtroppo, questo era tuo pesare, ma desideravi comunque cercare di vedere con gli occhi corporei cosa invisibile.\n",
      "\"La tua verità è: tu sei mio schiavo, o per questo è un giorno feriale, o per questo io non devo rispondere.\"\n",
      "Sì, concordo che dovesse avere grande libertà per permettergli di andare via.\n",
      "un notevole esempio per ogni uno che si curasse di fare e di pensare, il servo, il quale a noi era stato accusato, fu perdonato, e fu donata a lui una grande quantità di denaro.\n",
      "Che mi sarebbe stato disgrazioso se fossi stato io a commettere quello che il servo fece e la pena di Platone avesse meritato lo stesso.\n",
      "Mostro massimamente le sue forze, diventando re in questa città natia, dove era schiavo; il quale tenne l'impero per molto tempo.\n",
      "l'anima modifica la sua forza in virtù della proprietà di quel corpo con cui si unisce.\n",
      "Sono due già non nell'umano carne, ma nell' spirito, cioè Dio, e l'anima. In altre parole, San Paolo dice: Chi si avvicina a Dio è uno spirito.\n",
      "Per quanto Lucano lo disse, noi vi raccontiamo. Lì, quando l'anima di Pompeo sentì la chiarezza di Lasus, ella lo riconobbe prima in grande.\n",
      "\"Siccome dolore è sentire, quando l'uso delle armi e il sforzo ti rifiutano, con gran vergogna, come pecore siamo.\"\n",
      "Egli, Cristo, non ebbe fastidio di udire quei paroli.\n",
      "\"The crowd of those whom you have been able to see and observe in the study, and of those whose hands and lances only I can remember.\")\n",
      "ascoltare belle storie e olfattare belli fiori, come e quando e quanto conveniva.\n",
      "Il re entrò in un giardino dietro all'albergo suo, quasi come se andasse a riflettere.\n",
      "\"Ma io desideroso volo là dove io non posso andare con il corpo, con la mente vi vado.\"\n",
      "Tutto quel tumulto di uccelli si alzò in volo dietro all'aquila.\n",
      "Vede anche le ragioni del volo degli uccelli e di tutte le cose giudica veramente.\n",
      "Per il suo orgoglio, questo uccello volava in alto a quel punto.\n",
      "\"Gorgona, io desidero possedere questa qualità come un uccello nel cielo.\"\n",
      "quando si giurano nella matricola per Dio, per Cristo, e per lo Spirito Santo.\n",
      "per necessità riduco io, secondo il tuo comandamento, san padre Agostino, le battaglie già combattute nel mondo.\n",
      "\"Avrebbero avuto memoria molto superiore per il re, quindi il suo nome reale sempre fu sacro e glorioso nella nostra città, e se fossero stati compagni, il loro nome santo sarebbe stato lo stesso.\"\n",
      "Non voglio apparire superbo per proposito santo, e voto la verginità guardando le sue lodi.\n",
      "San Agostino scrisse un libro chiamato \"La Città di Dio\" di Agostino.\n",
      "Gregorio. Non l'ho mai sentito avere un maestro; ma il dono del Santo Spirito non si può limitare alla legge.\n",
      "I mercanti fiorentini navigavano in nave per andare oltre mare.\n",
      "Quando avrai nel cavaliere i segni visti non cessare di diminuire, perché nelle battaglie sono più utili i forti che i grandi.\n",
      "\"e, in modo ancora più grave, o essere catturati, o invece fuggire, e lasciare il proprio Comune sconfitto.\"\n",
      "Se noi non fossimo in fretta a fuggire, noi saremmo tutti morti.\n",
      "Tarco cretese, che poteva fuggire in aiuto dei nemici, tuttavia abbandonare i nobilissimi cavalleri achei che stavano vicini a lui facesse vergogna.\n",
      "e l'accogliimento fa grandi cose, cioè mantenere pace e amore per Dio e il prossimo, creare città, castelli e magioni.\n",
      "colui che ancora non sa amare il prossimo come se stesso inizia a temere i giudizi di Dio.\n",
      "L'uccello, dopo aver piumate le ali, non fugge in salvo, nemmeno il selvaggio maiale uscirebbe bene dalle rete in cui cade.\n",
      "Io gli aprisi, e quelli fuggirono. E che bisogno è, che il tuo cuore resti chiuso al tuo marito Cristo?\n",
      "\"Quindi, Catellina, e tu non puoi tranquillamente vivere qui, hai dubbi di andartene in qualunque terra e vivere questa vita nascondendoti negli abbandonati luoghi?\"\n",
      "Questi due, volontariamente contro la volontà del senato, rimasero nell'ufficio del tribunato e furono uccisi dalla plebe, inflammandola i padri coscritti.\n",
      "agli giovani, che si affidano la difesa delle province e la sorte di tutta la battaglia.\n",
      "Dal monti Romani si fecero nuovi nemici; contro di essi fu combattuta con varia fortuna: perché nella prima battaglia, essendo console Valerio, morirono MMMD romani.\n",
      "noi siam partiti per dovere verso la città, e tutti noi siam stati spinti da fama e da una buona avventura.\n",
      "pregatevi per me agli dèi; le vostre preghiere valgono: e chi avrebbe vinto questa battaglia si chiedeva; ma io non sono stato sconfitto da lui.\n",
      "In una villa chiamata Vitermina, se i principi di scherani avessero probabilmente corso a quel tempo per vedere ciò che accadeva, Scipione alloggiò nella casa per prevenire forse loro forze.\n",
      "contro di lui e contro le sue sorelle, contro il regno e contro l'alto prezio della sua nobiltà e della sua famiglia.\n",
      "Quando la nave si imbarcò e salpò in mare aperto per attraversare questo pericoloso passaggio, l'aria divenne nebulosa e piovosa.\n",
      "Non salì su l'argine del fosso e su lo steccato, se da alto si potesse difendere, o in qualche modo passare oltre e salvare.\n",
      "\"Il occhio dell'intelligenza è più alto. Perciò, oltrepassata la grandezza dell'università, quella stessa forma semplice vede nella sottile vista.\"\n",
      "Se l'occhio è un nobile membro del corpo dell'uomo, allora la salutazione è una nobile parte della pistola, in quanto illumina tutta la lettera come occhio illumina l'uomo.\n",
      "Ionici, essendo nati da quelli di Sparta e formati da essa nobile città greca dei Lacedemoni.\n",
      "Un uomo ricco e nobile si chiamava Orgentore.\n",
      "\"Purtroppo, se qualcosa nobile e alto è il nostro avversario, non meno commendabile è sapere mostrare clemenza.\"\n",
      "Alexandri, suo genero e figliolo di Phausonia, gentile giovane di Macedonia, rimasto in un luogo chiuso senza guardia, è morto.\n",
      "Alcuni sono ricchi e gentili, ma lamentano siché desiderano avere una altra moglie chequella loro hanno.\n",
      "Pietro, mostrato il popolo Gentile in figura, gli fu detto: uccidi, e mangia.\n",
      "il gentiluomo lo fece uscire dal suo impegno, in quel in cui lo aveva tenuto impegnato. Egli accordò, lo fece uscire e ne fece una scrittura.\n",
      "L'oro arriverà dall'Aquilone. Chi si intendiamo noi con Aquilone, se non il popolo Gentile congelato dal freddo del peccato, quel popolo tenne sotto il giogo della sua tirannia.\n",
      "Siete tra me e te: con noi non puoi più a lungo rimanere, poichè non lo sopporto e non ti lascerò.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_cleaned.csv')\n",
    "df['mistral'] = ''\n",
    "\n",
    "# Process each row\n",
    "for idx, row in df.iterrows():\n",
    "    # Create messages with current prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Sei un traduttore dall'italiano antico all'italiano moderno. Traduci una frase in italiano moderno e rispondi solo con: La traduzione è:<traduzione>. Non aggiungere altro pena la morte. Usa solo l'italiano e nessun'altra lingua nella traduzione.\"},\n",
    "        {\"role\": \"user\", \"content\": row['Sentence']} \n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "    attention_mask = torch.ones_like(tokens)\n",
    "\n",
    "    # Move to device\n",
    "    model_inputs1 = tokens.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    # Generate with attention mask\n",
    "    generated_ids1 = model.generate(\n",
    "        model_inputs1, \n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=1000, \n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    new_tokens = generated_ids1[0][len(tokens[0]):]\n",
    "    decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    translation = decoded.split(\"La traduzione è:\")[-1].strip()\n",
    "    #remove any part between ( and  )\n",
    "    translation = translation.split('(')[0].strip()\n",
    "    #remove anything after the \\n character\n",
    "    translation = translation.split('\\n')[0].strip() \n",
    "    print(translation)\n",
    "    \n",
    "    # Store translation\n",
    "    df.at[idx, 'Mistral 7b-instruction'] = translation\n",
    "\n",
    "# Save updated dataframe to dataset_deepseek.csv\n",
    "df.to_csv('./dataset/dataset_mistral.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e06c4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the vram memory\n",
    "torch.cuda.empty_cache()\n",
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327b390",
   "metadata": {},
   "source": [
    "## Prometeus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe31b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_eval.prompts import ABSOLUTE_PROMPT, SCORE_RUBRIC_TEMPLATE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import pandas\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615c390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Unbabel/M-Prometheus-3B\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Unbabel/M-Prometheus-3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af559e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Mistral 7b-instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brunetto Latini</td>\n",
       "      <td>1260-61</td>\n",
       "      <td>fior.</td>\n",
       "      <td>quella guerra ben fatta l' opera perché etc. E...</td>\n",
       "      <td>Quella guerra fu bene condotta, ma da una part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bono Giamboni</td>\n",
       "      <td>1292</td>\n",
       "      <td>fior.</td>\n",
       "      <td>crudele, e di tutte le colpe pigli vendetta, c...</td>\n",
       "      <td>\"Crudele, e di tutte le colpe prende vendetta,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valerio Massimo (red. V1</td>\n",
       "      <td>1336</td>\n",
       "      <td>fior.</td>\n",
       "      <td>Non d' altra forza d' animo fue ornato Ponzio ...</td>\n",
       "      <td>\"Ponzio Aufidiano, cavaliere romano, non fu ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucano volg. (ed. Marinoni)</td>\n",
       "      <td>1330/40</td>\n",
       "      <td>prat.</td>\n",
       "      <td>Se questo piace a tutti e se 'l tempo hae biso...</td>\n",
       "      <td>Se questo piace a tutti e se il tempo ha bisog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brunetto Latini</td>\n",
       "      <td>1260-61</td>\n",
       "      <td>fior.</td>\n",
       "      <td>Officio di questa arte pare che sia dicere app...</td>\n",
       "      <td>Sembra che questa arte faccia dire appositamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Grazia di Meo</td>\n",
       "      <td>1343</td>\n",
       "      <td>tosc.</td>\n",
       "      <td>Alchuno è riccho e gentile, ma lamentasi che v...</td>\n",
       "      <td>Alcuni sono ricchi e gentili, ma lamentano sic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Zanobi da Strada</td>\n",
       "      <td>1361</td>\n",
       "      <td>tosc.</td>\n",
       "      <td>Pietro, essendogli mostrato in figura il popul...</td>\n",
       "      <td>Pietro, mostrato il popolo Gentile in figura, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Declamazioni di Seneca</td>\n",
       "      <td>1392</td>\n",
       "      <td>tosc.</td>\n",
       "      <td>pregollo che lo liberasse di quella obbligazio...</td>\n",
       "      <td>il gentiluomo lo fece uscire dal suo impegno, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Giovanni da San Miniato</td>\n",
       "      <td>1415</td>\n",
       "      <td>tosc.</td>\n",
       "      <td>L'oro verrà dall'Aquilone. Che figuriamo noi p...</td>\n",
       "      <td>L'oro arriverà dall'Aquilone. Chi si intendiam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Prima catilinaria volg. (red. A)</td>\n",
       "      <td>1294</td>\n",
       "      <td>fior.</td>\n",
       "      <td>sia in mezzo tra me e te: con noi non puo' tu ...</td>\n",
       "      <td>Siete tra me e te: con noi non puoi più a lung...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Author     Date Region  \\\n",
       "0                    Brunetto Latini  1260-61  fior.   \n",
       "1                      Bono Giamboni     1292  fior.   \n",
       "2           Valerio Massimo (red. V1     1336  fior.   \n",
       "3        Lucano volg. (ed. Marinoni)  1330/40  prat.   \n",
       "4                    Brunetto Latini  1260-61  fior.   \n",
       "..                               ...      ...    ...   \n",
       "92                     Grazia di Meo     1343  tosc.   \n",
       "93                  Zanobi da Strada     1361  tosc.   \n",
       "94            Declamazioni di Seneca     1392  tosc.   \n",
       "95           Giovanni da San Miniato     1415  tosc.   \n",
       "96  Prima catilinaria volg. (red. A)     1294  fior.   \n",
       "\n",
       "                                             Sentence  \\\n",
       "0   quella guerra ben fatta l' opera perché etc. E...   \n",
       "1   crudele, e di tutte le colpe pigli vendetta, c...   \n",
       "2   Non d' altra forza d' animo fue ornato Ponzio ...   \n",
       "3   Se questo piace a tutti e se 'l tempo hae biso...   \n",
       "4   Officio di questa arte pare che sia dicere app...   \n",
       "..                                                ...   \n",
       "92  Alchuno è riccho e gentile, ma lamentasi che v...   \n",
       "93  Pietro, essendogli mostrato in figura il popul...   \n",
       "94  pregollo che lo liberasse di quella obbligazio...   \n",
       "95  L'oro verrà dall'Aquilone. Che figuriamo noi p...   \n",
       "96  sia in mezzo tra me e te: con noi non puo' tu ...   \n",
       "\n",
       "                               Mistral 7b-instruction  \n",
       "0   Quella guerra fu bene condotta, ma da una part...  \n",
       "1   \"Crudele, e di tutte le colpe prende vendetta,...  \n",
       "2   \"Ponzio Aufidiano, cavaliere romano, non fu ar...  \n",
       "3   Se questo piace a tutti e se il tempo ha bisog...  \n",
       "4   Sembra che questa arte faccia dire appositamen...  \n",
       "..                                                ...  \n",
       "92  Alcuni sono ricchi e gentili, ma lamentano sic...  \n",
       "93  Pietro, mostrato il popolo Gentile in figura, ...  \n",
       "94  il gentiluomo lo fece uscire dal suo impegno, ...  \n",
       "95  L'oro arriverà dall'Aquilone. Chi si intendiam...  \n",
       "96  Siete tra me e te: con noi non puoi più a lung...  \n",
       "\n",
       "[97 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_model_mistral = pandas.read_csv('./dataset/dataset_mistral_full.csv')\n",
    "dataset_model_deepseek = pandas.read_csv('./dataset/dataset_deepseek_full.csv')\n",
    "dataset_golden = pandas.read_csv('./dataset/dataset_goldenLabel.csv')\n",
    "dataset_model_mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d88571b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instruction(sentence_to_translate, response, golden_label):\n",
    "    instruction = f\"The user needs to translate sentences from arcaic italian to modern italian. He provide this sentence to translate: {sentence_to_translate}\",\n",
    "    response = f\"{response}\"\n",
    "    reference_answer = f\"{golden_label}\",\n",
    "    \n",
    "    rubric_data = {\n",
    "      \"criteria\":\"Is the model proficient in traqnslating archaic Italian sentences into modern Italian?\",\n",
    "      \"score1_description\":\"The model isn't capable of translating archaic Italian sentences into modern Italian, producing responses that are either completely incorrect or irrelevant.\",\n",
    "      \"score2_description\":\"The model is capable of translating some archaic Italian sentences into modern Italian, but the translations are often inaccurate or incomplete, failing to capture the essence of the original text.\",\n",
    "      \"score3_description\":\"The model typically translates archaic Italian sentences into modern Italian with moderate accuracy, but may struggle with complex phrases or idiomatic expressions, leading to occasional inaccuracies.\",\n",
    "      \"score4_description\":\"The model consistently translates archaic Italian sentences into modern Italian with high accuracy, capturing the essence of the original text and handling most idiomatic expressions effectively.\",\n",
    "      \"score5_description\":\"The model excels in translating archaic Italian sentences into modern Italian, demonstrating a deep understanding of both the source and target languages, and consistently producing translations that are not only accurate but also stylistically appropriate.\"\n",
    "    }\n",
    "    \n",
    "    score_rubric = SCORE_RUBRIC_TEMPLATE.format(**rubric_data)\n",
    "    \n",
    "    ABS_SYSTEM_PROMPT = \"You are a helpful assistant that grades the quality of responses to user instructions. You will be given an instruction, a response, and a rubric. Your task is to assign a score based on the rubric. Your task is to assign a score based on the rubric in the following format 'Score:'.\"\n",
    "    ABSOLUTE_PROMPT = f\"Instruction: {{instruction}}\\n\\nResponse: {{response}}\\n\\nRubric: {{rubric}}\\n\\nReference Answer: {{reference_answer}}\\n\\nFeedback:\"\n",
    "    user_content = ABSOLUTE_PROMPT.format(\n",
    "        instruction=instruction,\n",
    "        response=response,\n",
    "        rubric=score_rubric,\n",
    "        reference_answer=reference_answer[0]\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": ABS_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def get_most_frequent_by_index(data):\n",
    "  return [max(set(column), key=column.count) for column in zip(*data)]\n",
    "\n",
    "def extract_score(text):\n",
    "    \"\"\"\n",
    "    Extract score from feedback text using regex\n",
    "    \"\"\"\n",
    "    # Primary pattern - looks for \"score of [number]\" after \"Feedback:\"\n",
    "    pattern1 = r'(?i)(?:feedback:.*?)score\\s+of\\s+(\\d+)'\n",
    "    \n",
    "    # Alternative pattern - more general \"score [anything] [number]\"\n",
    "    pattern2 = r'(?i)(?:feedback:.*?)score\\s+.*?\\s+(\\d+)'\n",
    "\n",
    "    pattern3 = r'(?i)(?:feedback:.*?)score\\b\\s*:?\\s*.*?(\\d+)'\n",
    "    # Try the more specific pattern first\n",
    "    match = re.search(pattern1, text, re.DOTALL)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    # If that doesn't work, try the more general pattern\n",
    "    match = re.search(pattern2, text, re.DOTALL)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "\n",
    "    match = re.search(pattern3, text, re.DOTALL)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(dataset_golden)\n",
    "list_of_messages_m = []\n",
    "list_of_messages_d = []\n",
    "for i in range(0, length):\n",
    "    sentence_to_translate = dataset_golden[\"Sentence\"][i]\n",
    "    response_mistral = dataset_model_mistral[\"Mistral 7b-instruction\"][i]\n",
    "    response_deepseek = dataset_model_deepseek[\"Deepseek R1 qwen-8b\"][i]\n",
    "    golden_label = dataset_golden[\"goldenLabel\"][i]\n",
    "    message_mistral = create_instruction(sentence_to_translate, response_mistral, golden_label)\n",
    "    message_deepseek = create_instruction(sentence_to_translate, response_deepseek, golden_label)\n",
    "    list_of_messages_m.append(message_mistral)\n",
    "    list_of_messages_d.append(message_deepseek)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d8159",
   "metadata": {},
   "source": [
    "### Evaluating Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e08a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Round n. 0----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 97/97 [07:27<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Round n. 1----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 97/97 [06:49<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Round n. 2----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 97/97 [07:29<00:00,  4.63s/it]\n"
     ]
    }
   ],
   "source": [
    "rounds = 3\n",
    "\n",
    "all_outputs_m = []\n",
    "all_scores_m = []\n",
    "\n",
    "print(\"Starting evaluation for Mistral 7B-Instruct\")\n",
    "for i in range(rounds):\n",
    "    print(f\"\\n---- Round n. {i}----\\n\")\n",
    "    list_of_scores_for_round = []\n",
    "    list_of_outputs_for_round = []\n",
    "    for msg in tqdm(list_of_messages_m, desc=\"Processing data\"):\n",
    "        encodeds = tokenizer.apply_chat_template(msg, return_tensors=\"pt\", return_dict = True)\n",
    "        model_inputs = encodeds['input_ids'].to(device)\n",
    "        attention_mask = encodeds['attention_mask'].to(device)\n",
    "        model.to(device)\n",
    "        \n",
    "        generated_ids = model.generate(model_inputs, max_new_tokens=1000, attention_mask=attention_mask, do_sample=True)\n",
    "        decoded = tokenizer.batch_decode(generated_ids)\n",
    "        list_of_outputs_for_round.append(decoded[0])\n",
    "        output = extract_score(decoded[0])\n",
    "        list_of_scores_for_round.append(output)\n",
    "    all_outputs_m.append(list_of_outputs_for_round)\n",
    "    all_scores_m.append(list_of_scores_for_round)\n",
    "\n",
    "final_scores_m = get_most_frequent_by_index(all_scores_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c0e9c",
   "metadata": {},
   "source": [
    "### Evaluating Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85072cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 3\n",
    "\n",
    "all_outputs_d = []\n",
    "all_scores_d = []\n",
    "\n",
    "print(\"Starting evaluation for Deepseek R1 Qwen-8B\")\n",
    "for i in range(rounds):\n",
    "    print(f\"\\n---- Round n. {i}----\\n\")\n",
    "    list_of_scores_for_round = []\n",
    "    list_of_outputs_for_round = []\n",
    "    for msg in tqdm(list_of_messages_d, desc=\"Processing data\"):\n",
    "        encodeds = tokenizer.apply_chat_template(msg, return_tensors=\"pt\", return_dict = True)\n",
    "        model_inputs = encodeds['input_ids'].to(device)\n",
    "        attention_mask = encodeds['attention_mask'].to(device)\n",
    "        model.to(device)\n",
    "        \n",
    "        generated_ids = model.generate(model_inputs, max_new_tokens=1000, attention_mask=attention_mask, do_sample=True)\n",
    "        decoded = tokenizer.batch_decode(generated_ids)\n",
    "        list_of_outputs_for_round.append(decoded[0])\n",
    "        output = extract_score(decoded[0])\n",
    "        list_of_scores_for_round.append(output)\n",
    "    all_outputs_d.append(list_of_outputs_for_round)\n",
    "    all_scores_d.append(list_of_scores_for_round)\n",
    "    \n",
    "final_scores_d = get_most_frequent_by_index(all_scores_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3666c3",
   "metadata": {},
   "source": [
    "### Cleaning cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07f9723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del tokenizer\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3af22",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c111c1e",
   "metadata": {},
   "source": [
    "#### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41801413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Author                  97 non-null     object \n",
      " 1   Date                    97 non-null     object \n",
      " 2   Region                  97 non-null     object \n",
      " 3   Sentence                97 non-null     object \n",
      " 4   Mistral 7b-instruction  97 non-null     object \n",
      " 5   prometeus vote          96 non-null     float64\n",
      " 6   golden_label            97 non-null     object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 5.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_evaluated_mistral = dataset_model_mistral.copy()\n",
    "dataset_evaluated_mistral['p_mistral_vote'] = final_scores_m\n",
    "dataset_evaluated_mistral['golden_label'] = dataset_golden[\"goldenLabel\"]\n",
    "dataset_evaluated_mistral.info()\n",
    "# Save the evaluated dataset\n",
    "dataset_evaluated_mistral.to_csv('./dataset/dataset_evaluated_mistral.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eec09f",
   "metadata": {},
   "source": [
    "#### Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_evaluated_deepseek = dataset_model_deepseek.copy()\n",
    "dataset_evaluated_deepseek['p_mistral_vote'] = final_scores_d\n",
    "dataset_evaluated_deepseek['golden_label'] = dataset_golden[\"goldenLabel\"]\n",
    "dataset_evaluated_deepseek.info()\n",
    "# Save the evaluated dataset\n",
    "dataset_evaluated_deepseek.to_csv('./dataset/dataset_evaluated_deepseek.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a7408",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eba2ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "manual = pd.read_csv('./dataset/dataset_sub_20_m_eval.csv')\n",
    "mistral = pd.read_csv('./dataset/dataset_evaluated_mistral.csv')\n",
    "deepseek = pd.read_csv('./dataset/dataset_evaluated_deepseek.csv')\n",
    "\n",
    "# select only the same sentence present in both mistral/deepseek and manual\n",
    "mistral_sub = mistral[mistral['golden_label'].isin(manual['goldenLabel'])]\n",
    "deepseek_sub = deepseek[deepseek['golden_label'].isin(manual['goldenLabel'])]\n",
    "\n",
    "# order the mistral_sub, deepseek_sub and manual by golden_label\n",
    "mistral_sub = mistral_sub.sort_values(by='golden_label').reset_index(drop=True)\n",
    "deepseek_sub = deepseek_sub.sort_values(by='golden_label').reset_index(drop=True)\n",
    "manual = manual.sort_values(by='goldenLabel').reset_index(drop=True)\n",
    "\n",
    "# get the scores\n",
    "mistral_scores = mistral_sub['p_mistral_vote'].values\n",
    "deepseek_scores = deepseek_sub['p_deepseek_vote'].values\n",
    "manual_scores_d = manual['user_eval_deepseek'].values\n",
    "manual_scores_m = manual['user_eval_mistral'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d824a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for Mistral: 0.2086\n",
      "Cohen's Kappa for Deepseek: -0.0667\n",
      "Spearman's correlation for Mistral: 0.1701\n",
      "Spearman's correlation for Deepseek: 0.1345\n"
     ]
    }
   ],
   "source": [
    "# Calculate Cohen's Kappa for Mistral\n",
    "kappa_mistral = cohen_kappa_score(manual_scores_m, mistral_scores)\n",
    "# Calculate Cohen's Kappa for Deepseek\n",
    "kappa_deepseek = cohen_kappa_score(manual_scores_d, deepseek_scores)\n",
    "# Calculate Spearman's correlation for Mistral\n",
    "spearman_mistral, _ = spearmanr(manual_scores_m, mistral_scores)\n",
    "# Calculate Spearman's correlation for Deepseek\n",
    "spearman_deepseek, _ = spearmanr(manual_scores_d, deepseek_scores)\n",
    "# Print the results\n",
    "print(f\"Cohen's Kappa for Mistral: {kappa_mistral:.4f}\")\n",
    "print(f\"Cohen's Kappa for Deepseek: {kappa_deepseek:.4f}\")\n",
    "print(f\"Spearman's correlation for Mistral: {spearman_mistral:.4f}\")\n",
    "print(f\"Spearman's correlation for Deepseek: {spearman_deepseek:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cf27169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Mistral: 2.6500\n",
      "Mean Squared Error for Deepseek: 2.3500\n"
     ]
    }
   ],
   "source": [
    "# calculate the MSE for mistral and deepseek\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_mistral = mean_squared_error(manual_scores_m, mistral_scores)\n",
    "mse_deepseek = mean_squared_error(manual_scores_d, deepseek_scores)\n",
    "print(f\"Mean Squared Error for Mistral: {mse_mistral:.4f}\")\n",
    "print(f\"Mean Squared Error for Deepseek: {mse_deepseek:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
