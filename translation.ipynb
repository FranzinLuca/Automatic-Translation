{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b5cf26",
   "metadata": {},
   "source": [
    "## Deepseek R1 qwen3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137fd436",
   "metadata": {},
   "source": [
    "the model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"unsloth/DeepSeek-R1-0528-Qwen3-8B-bnb-4bit\"\n",
    "device = \"cuda\" \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d45ea",
   "metadata": {},
   "source": [
    "an example of one translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7efd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Marco Cornelio ch'era de' dieci compagni, studiosamente  si riservò di parlare all'ultimo.\"\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"you are a translator from old italian to model italian. you take a sentence in old italian and you answer only with: La traduzione è:<translation> . Don't add anything else. Translate only in italian\"},\n",
    "        {\"role\": \"system\", \"content\": \"only use italian and no other language in the translation\"},\n",
    "        {\"role\": \"user\", \"content\": prompt} \n",
    "    ]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=5000,\n",
    "    do_sample=True, \n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "\n",
    "new_tokens = generated_ids[0][len(model_inputs[0]):]\n",
    "decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "decoded = decoded.split(\"La traduzione è:\")[-1].strip()\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4603e08",
   "metadata": {},
   "source": [
    "the code to translate all the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('dataset_cleaned.csv')\n",
    "\n",
    "# Create new column for translations\n",
    "df['Deepseek R1 qwen-8b'] = ''\n",
    "\n",
    "# Process each row\n",
    "for idx, row in df.iterrows():\n",
    "    # Create messages with current prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"you are a translator from old italian to model italian. you take a sentence in old italian and you answer only with: La traduzione è:<translation> . Don't add anything else. Translate only in italian\"},\n",
    "        {\"role\": \"system\", \"content\": \"only use italian and no other language in the translation\"},\n",
    "        {\"role\": \"user\", \"content\": row['Sentence']} \n",
    "    ]\n",
    "    \n",
    "    # Prepare input\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate translation\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=10000,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    # Decode and clean up response\n",
    "    new_tokens = generated_ids[0][len(model_inputs[0]):]\n",
    "    decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    translation = decoded.split(\"La traduzione è:\")[-1].strip()    \n",
    "    print(translation)\n",
    "    \n",
    "    # Store translation\n",
    "    df.at[idx, 'Deepseek R1 qwen-8b'] = translation\n",
    "\n",
    "# Save updated dataframe to dataset_deepseek.csv\n",
    "df.to_csv('./dataset/dataset_deepseek.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6675dd",
   "metadata": {},
   "source": [
    "cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724449d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the vram memory\n",
    "torch.cuda.empty_cache()\n",
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7705f8",
   "metadata": {},
   "source": [
    "## Mistral Mistral-7B-Instruct-v0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1200df22",
   "metadata": {},
   "source": [
    "the model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" \n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a026674",
   "metadata": {},
   "source": [
    "one translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91108ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"la moltitudine de' quali tu ài potuto vedere e riguardare lo studio e poco dinanzi udire le voci, e lle cui mani e lance apena posso ritenere.\"\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Sei un traduttore dall'italiano antico all'italiano moderno. Traduci una frase in italiano moderno e rispondi solo con: La traduzione è:<traduzione>. Non aggiungere altro pena la morte. Usa solo l'italiano e nessun'altra lingua nella traduzione.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt} \n",
    "    ]\n",
    "\n",
    "tokens = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "attention_mask = torch.ones_like(tokens)\n",
    "\n",
    "# Move to device\n",
    "model_inputs1 = tokens.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "\n",
    "# Generate with attention mask\n",
    "generated_ids1 = model.generate(\n",
    "    model_inputs1, \n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=1000, \n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Decode only the new tokens (exclude the input)\n",
    "new_tokens = generated_ids1[0][len(tokens[0]):]\n",
    "decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd11146",
   "metadata": {},
   "source": [
    "code for all database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_cleaned.csv')\n",
    "df['mistral'] = ''\n",
    "\n",
    "# Process each row\n",
    "for idx, row in df.iterrows():\n",
    "    # Create messages with current prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Sei un traduttore dall'italiano antico all'italiano moderno. Traduci una frase in italiano moderno e rispondi solo con: La traduzione è:<traduzione>. Non aggiungere altro pena la morte. Usa solo l'italiano e nessun'altra lingua nella traduzione.\"},\n",
    "        {\"role\": \"user\", \"content\": row['Sentence']} \n",
    "    ]\n",
    "\n",
    "    tokens = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "    attention_mask = torch.ones_like(tokens)\n",
    "\n",
    "    # Move to device\n",
    "    model_inputs1 = tokens.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    # Generate with attention mask\n",
    "    generated_ids1 = model.generate(\n",
    "        model_inputs1, \n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=1000, \n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    new_tokens = generated_ids1[0][len(tokens[0]):]\n",
    "    decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    translation = decoded.split(\"La traduzione è:\")[-1].strip()\n",
    "    #remove any part between ( and  )\n",
    "    translation = translation.split('(')[0].strip()\n",
    "    #remove anything after the \\n character\n",
    "    translation = translation.split('\\n')[0].strip() \n",
    "    print(translation)\n",
    "    \n",
    "    # Store translation\n",
    "    df.at[idx, 'Mistral 7b-instruction'] = translation\n",
    "\n",
    "# Save updated dataframe to dataset_deepseek.csv\n",
    "df.to_csv('./dataset/dataset_mistral.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e06c4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the vram memory\n",
    "torch.cuda.empty_cache()\n",
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327b390",
   "metadata": {},
   "source": [
    "## Prometeus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe31b197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T07:59:07.323281Z",
     "iopub.status.busy": "2025-06-21T07:59:07.322549Z",
     "iopub.status.idle": "2025-06-21T07:59:18.463191Z",
     "shell.execute_reply": "2025-06-21T07:59:18.462629Z",
     "shell.execute_reply.started": "2025-06-21T07:59:07.323250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from prometheus_eval.prompts import ABSOLUTE_PROMPT, SCORE_RUBRIC_TEMPLATE\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c390c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T07:59:21.510933Z",
     "iopub.status.busy": "2025-06-21T07:59:21.510518Z",
     "iopub.status.idle": "2025-06-21T08:00:34.945263Z",
     "shell.execute_reply": "2025-06-21T08:00:34.944325Z",
     "shell.execute_reply.started": "2025-06-21T07:59:21.510908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model_name = \"prometheus-eval/prometheus-7b-v2.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, device_map=\"auto\", torch_dtype=torch.float16,\n",
    "                                            offload_folder=\"offload_prometheus\", offload_buffers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af559e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T08:29:27.432047Z",
     "iopub.status.busy": "2025-06-21T08:29:27.431597Z",
     "iopub.status.idle": "2025-06-21T08:29:27.516066Z",
     "shell.execute_reply": "2025-06-21T08:29:27.515231Z",
     "shell.execute_reply.started": "2025-06-21T08:29:27.432023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_model_mistral = pandas.read_csv('dataset/dataset_mistral.csv')\n",
    "dataset_model_deepseek = pandas.read_csv('dataset/dataset_deepseek.csv')\n",
    "dataset_model_qwen = pandas.read_csv('dataset/dataset_qwen.csv')\n",
    "dataset_golden = pandas.read_csv('dataset/dataset_goldenLabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d88571b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T09:10:46.761840Z",
     "iopub.status.busy": "2025-06-21T09:10:46.761168Z",
     "iopub.status.idle": "2025-06-21T09:10:46.768001Z",
     "shell.execute_reply": "2025-06-21T09:10:46.767337Z",
     "shell.execute_reply.started": "2025-06-21T09:10:46.761817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_instruction(sentence_to_translate, response, golden_label):\n",
    "    instruction = f\"Translate the following archaic Italian sentence into modern Italian: {sentence_to_translate}\",\n",
    "    response = f\"{response}\"\n",
    "    reference_answer = f\"{golden_label}\",\n",
    "    \n",
    "    rubric_data = {\n",
    "      \"criteria\": \"Archaic to Modern Italian Translation Quality\",\n",
    "      \"score1_description\": \"The translation is not provided, is unintelligible, or has completely lost the essential meaning of the original sentence.\",\n",
    "      \"score2_description\": \"The translation is difficult to understand. It contains major errors (in grammar, logic, or word choice) that significantly obscure or partially change the original meaning.\",\n",
    "      \"score3_description\": \"The translation preserves the core meaning and is understandable, but contains noticeable flaws. The sentence may sound unnatural or awkward due to literal translations of archaic structures, or have minor grammatical errors that don't obscure the meaning.\",\n",
    "      \"score4_description\": \"The translation is grammatically correct, accurately preserves the original meaning, and reads as natural, fluent modern Italian.\",\n",
    "      \"score5_description\": \"The translation meets all criteria for a Score 4 (it is accurate, correct, and fluent) AND it also successfully captures the original author's subtle style, tone, and nuance.\"\n",
    "    }\n",
    "    \n",
    "    score_rubric = SCORE_RUBRIC_TEMPLATE.format(**rubric_data)\n",
    "    \n",
    "    ABS_SYSTEM_PROMPT = \"You are a helpful assistant that grades the quality of responses to user instructions. You will be given an instruction, a response, and a rubric. Your task is to assign a score based on the rubric. Your should STRICTLY give ALWAYS the score in this style --> [Score: ].\"\n",
    "    ABSOLUTE_PROMPT = f\"Instruction: {{instruction}}\\n\\nResponse: {{response}}\\n\\nRubric: {{rubric}}\\n\\nReference Answer: {{reference_answer}}\\n\\nFeedback:\"\n",
    "    user_content = ABSOLUTE_PROMPT.format(\n",
    "        instruction=instruction,\n",
    "        response=response,\n",
    "        rubric=score_rubric,\n",
    "        reference_answer=reference_answer[0]\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": ABS_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def extract_score(text):\n",
    "    \"\"\"\n",
    "    Extract score from feedback text using regex\n",
    "    \"\"\"\n",
    "    pattern = r'\\[Score:\\s*(\\d+)\\]'\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa44e8b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T08:29:30.372035Z",
     "iopub.status.busy": "2025-06-21T08:29:30.371471Z",
     "iopub.status.idle": "2025-06-21T08:29:30.381998Z",
     "shell.execute_reply": "2025-06-21T08:29:30.381234Z",
     "shell.execute_reply.started": "2025-06-21T08:29:30.372016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "length = len(dataset_golden)\n",
    "list_of_messages_m = []\n",
    "list_of_messages_d = []\n",
    "list_of_messages_q = []\n",
    "for i in range(0, length):\n",
    "    sentence_to_translate = dataset_golden[\"Sentence\"][i]\n",
    "    response_mistral = dataset_model_mistral[\"Mistral 7b-instruction\"][i]\n",
    "    response_deepseek = dataset_model_deepseek[\"Deepseek R1 qwen-8b\"][i]\n",
    "    response_qwen = dataset_model_qwen[\"Qwen3-32b\"][i]\n",
    "    golden_label = dataset_golden[\"goldenLabel\"][i]\n",
    "    message_mistral = create_instruction(sentence_to_translate, response_mistral, golden_label)\n",
    "    message_deepseek = create_instruction(sentence_to_translate, response_deepseek, golden_label)\n",
    "    message_qwen = create_instruction(sentence_to_translate, response_qwen, golden_label)\n",
    "    list_of_messages_m.append(message_mistral)\n",
    "    list_of_messages_d.append(message_deepseek)\n",
    "    list_of_messages_q.append(message_qwen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d8159",
   "metadata": {},
   "source": [
    "### Evaluating Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e08a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T08:09:32.370129Z",
     "iopub.status.busy": "2025-06-21T08:09:32.369468Z",
     "iopub.status.idle": "2025-06-21T08:27:00.604687Z",
     "shell.execute_reply": "2025-06-21T08:27:00.604081Z",
     "shell.execute_reply.started": "2025-06-21T08:09:32.370098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_outputs_m = []\n",
    "all_scores_m = []\n",
    "\n",
    "print(\"Starting evaluation for Mistral 7B-Instruct\")\n",
    "model.to(device)\n",
    "pbar = tqdm(list_of_messages_m, desc=\"Processing data\")\n",
    "\n",
    "for msg in pbar:\n",
    "    encodeds = tokenizer.apply_chat_template(msg, return_tensors=\"pt\", return_dict = True)\n",
    "    model_inputs = encodeds['input_ids'].to(device)\n",
    "    attention_mask = encodeds['attention_mask'].to(device)\n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens=500, attention_mask=attention_mask, do_sample=False, pad_token_id=tokenizer.pad_token_id)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    all_outputs_m.append(decoded[0])\n",
    "    output = extract_score(decoded[0])\n",
    "    all_scores_m.append(output)\n",
    "    if all_scores_m:\n",
    "        avg_score = sum(all_scores_m) / len(all_scores_m)\n",
    "        pbar.set_postfix(last_score=output, avg_score=f'{avg_score:.2f}')\n",
    "print(all_scores_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c0e9c",
   "metadata": {},
   "source": [
    "### Evaluating Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85072cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T08:29:36.640016Z",
     "iopub.status.busy": "2025-06-21T08:29:36.639741Z",
     "iopub.status.idle": "2025-06-21T08:47:36.099588Z",
     "shell.execute_reply": "2025-06-21T08:47:36.098905Z",
     "shell.execute_reply.started": "2025-06-21T08:29:36.639996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_outputs_d = []\n",
    "all_scores_d = []\n",
    "model.to(device)\n",
    "\n",
    "print(\"Starting evaluation for Deepseek R1 Qwen-8B\")\n",
    "pbar = tqdm(list_of_messages_d, desc=\"Processing data\")\n",
    "for msg in pbar:\n",
    "    encodeds = tokenizer.apply_chat_template(msg, return_tensors=\"pt\", return_dict = True)\n",
    "    model_inputs = encodeds['input_ids'].to(device)\n",
    "    attention_mask = encodeds['attention_mask'].to(device)\n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens=500, attention_mask=attention_mask, do_sample=False, pad_token_id=tokenizer.pad_token_id)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    all_outputs_d.append(decoded[0])\n",
    "    output = extract_score(decoded[0])\n",
    "    all_scores_d.append(output)\n",
    "    if all_scores_d:\n",
    "        avg_score = sum(all_scores_d) / len(all_scores_d)\n",
    "        pbar.set_postfix(last_score=output, avg_score=f'{avg_score:.2f}')\n",
    "print(all_scores_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74feb2c9-fd2a-4a89-94e6-fb9e32261e34",
   "metadata": {},
   "source": [
    "### Evaluating Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865218c9-66be-4cf9-9808-dbc64fc21985",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_outputs_q = []\n",
    "all_scores_q = []\n",
    "model.to(device)\n",
    "\n",
    "print(\"Starting evaluation for Qwen3\")\n",
    "pbar = tqdm(list_of_messages_q, desc=\"Processing data\")\n",
    "for msg in pbar:\n",
    "    encodeds = tokenizer.apply_chat_template(msg, return_tensors=\"pt\", return_dict = True)\n",
    "    model_inputs = encodeds['input_ids'].to(device)\n",
    "    attention_mask = encodeds['attention_mask'].to(device)\n",
    "    generated_ids = model.generate(model_inputs, max_new_tokens=500, attention_mask=attention_mask, do_sample=False, pad_token_id=tokenizer.pad_token_id)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    all_outputs_q.append(decoded[0])\n",
    "    output = extract_score(decoded[0])\n",
    "    all_scores_q.append(output)\n",
    "    if all_scores_q:\n",
    "        avg_score = sum(all_scores_q) / len(all_scores_q)\n",
    "        pbar.set_postfix(last_score=output, avg_score=f'{avg_score:.2f}')\n",
    "print(all_scores_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3666c3",
   "metadata": {},
   "source": [
    "### Cleaning cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f9723e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:35:26.755846Z",
     "iopub.status.busy": "2025-06-20T18:35:26.755614Z",
     "iopub.status.idle": "2025-06-20T18:35:26.773688Z",
     "shell.execute_reply": "2025-06-20T18:35:26.773163Z",
     "shell.execute_reply.started": "2025-06-20T18:35:26.755830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "del tokenizer\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3af22",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c111c1e",
   "metadata": {},
   "source": [
    "#### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41801413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:35:26.775896Z",
     "iopub.status.busy": "2025-06-20T18:35:26.775699Z",
     "iopub.status.idle": "2025-06-20T18:35:26.805304Z",
     "shell.execute_reply": "2025-06-20T18:35:26.804627Z",
     "shell.execute_reply.started": "2025-06-20T18:35:26.775881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_evaluated_mistral = dataset_model_mistral.copy()\n",
    "dataset_evaluated_mistral['p_mistral_vote'] = all_scores_m\n",
    "dataset_evaluated_mistral['golden_label'] = dataset_golden[\"goldenLabel\"]\n",
    "dataset_evaluated_mistral.info()\n",
    "# Save the evaluated dataset\n",
    "dataset_evaluated_mistral.to_csv('./dataset_evaluated_mistral.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eec09f",
   "metadata": {},
   "source": [
    "#### Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaeffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:35:26.806119Z",
     "iopub.status.busy": "2025-06-20T18:35:26.805876Z",
     "iopub.status.idle": "2025-06-20T18:35:26.823484Z",
     "shell.execute_reply": "2025-06-20T18:35:26.822868Z",
     "shell.execute_reply.started": "2025-06-20T18:35:26.806104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_evaluated_deepseek = dataset_model_deepseek.copy()\n",
    "dataset_evaluated_deepseek['p_deepseek_vote'] = all_scores_d\n",
    "dataset_evaluated_deepseek['golden_label'] = dataset_golden[\"goldenLabel\"]\n",
    "dataset_evaluated_deepseek.info()\n",
    "# Save the evaluated dataset\n",
    "dataset_evaluated_deepseek.to_csv('./dataset_evaluated_deepseek.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c04ef7-8289-4480-9bcd-8555f4f96d30",
   "metadata": {},
   "source": [
    "#### Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d4d70-29ed-4fe7-a546-e14549178330",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_evaluated_qwen = dataset_model_qwen.copy()\n",
    "dataset_evaluated_qwen['p_qwen_vote'] = all_scores_q\n",
    "dataset_evaluated_qwen['golden_label'] = dataset_golden[\"goldenLabel\"]\n",
    "dataset_evaluated_qwen.info()\n",
    "# Save the evaluated dataset\n",
    "dataset_evaluated_qwen.to_csv('./dataset_evaluated_qwen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a7408",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eba2ffc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:35:26.824337Z",
     "iopub.status.busy": "2025-06-20T18:35:26.824144Z",
     "iopub.status.idle": "2025-06-20T18:35:26.858394Z",
     "shell.execute_reply": "2025-06-20T18:35:26.857809Z",
     "shell.execute_reply.started": "2025-06-20T18:35:26.824323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "manual = pd.read_csv('dataset/dataset_sub_20_m_eval.csv')\n",
    "mistral = pd.read_csv('dataset/dataset_evaluated_mistral.csv')\n",
    "deepseek = pd.read_csv('dataset/dataset_evaluated_deepseek.csv')\n",
    "qwen = pd.read_csv('dataset/dataset_evaluated_qwen.csv')\n",
    "\n",
    "# select only the same sentence present in both mistral/deepseek and manual\n",
    "mistral_sub = mistral[mistral['golden_label'].isin(manual['goldenLabel'])]\n",
    "deepseek_sub = deepseek[deepseek['golden_label'].isin(manual['goldenLabel'])]\n",
    "qwen_sub = qwen[qwen['golden_label'].isin(manual['goldenLabel'])]\n",
    "\n",
    "# order the mistral_sub, deepseek_sub and manual by golden_label\n",
    "mistral_sub = mistral_sub.sort_values(by='golden_label').reset_index(drop=True)\n",
    "deepseek_sub = deepseek_sub.sort_values(by='golden_label').reset_index(drop=True)\n",
    "qwen_sub = qwen_sub.sort_values(by='golden_label').reset_index(drop=True)\n",
    "manual = manual.sort_values(by='goldenLabel').reset_index(drop=True)\n",
    "\n",
    "# get the scores\n",
    "mistral_scores = mistral_sub['p_mistral_vote'].values\n",
    "deepseek_scores = deepseek_sub['p_deepseek_vote'].values\n",
    "qwen_scores = qwen_sub['p_qwen_vote'].values\n",
    "manual_scores_d = manual['deepseek_vote'].values\n",
    "manual_scores_m = manual['mistral_vote'].values\n",
    "manual_scores_q = manual['qwen_vote'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d824a5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:35:26.859670Z",
     "iopub.status.busy": "2025-06-20T18:35:26.859184Z",
     "iopub.status.idle": "2025-06-20T18:35:26.880211Z",
     "shell.execute_reply": "2025-06-20T18:35:26.879530Z",
     "shell.execute_reply.started": "2025-06-20T18:35:26.859645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for Mistral: 0.0058\n",
      "Cohen's Kappa for Deepseek: 0.2691\n",
      "Cohen's Kappa for Qwen: -0.0332\n",
      "Spearman's correlation for Mistral: 0.2134\n",
      "Spearman's correlation for Deepseek: 0.1781\n",
      "Spearman's correlation for Qwen: -0.1307\n"
     ]
    }
   ],
   "source": [
    "# Calculate Cohen's Kappa for Mistral\n",
    "kappa_mistral = cohen_kappa_score(manual_scores_m, mistral_scores)\n",
    "# Calculate Cohen's Kappa for Deepseek\n",
    "kappa_deepseek = cohen_kappa_score(manual_scores_d, deepseek_scores)\n",
    "# Calculate Cohen's Kappa for Qwen\n",
    "kappa_qwen = cohen_kappa_score(manual_scores_q, qwen_scores)\n",
    "\n",
    "# Calculate Spearman's correlation for Mistral\n",
    "spearman_mistral = spearmanr(manual_scores_m, mistral_scores).correlation\n",
    "# Calculate Spearman's correlation for Deepseek\n",
    "spearman_deepseek = spearmanr(manual_scores_d, deepseek_scores).correlation\n",
    "# Calculate Spearman's correlation for Qwen\n",
    "spearman_qwen = spearmanr(manual_scores_q, qwen_scores).correlation\n",
    "\n",
    "# Print the results\n",
    "print(f\"Cohen's Kappa for Mistral: {kappa_mistral:.4f}\")\n",
    "print(f\"Cohen's Kappa for Deepseek: {kappa_deepseek:.4f}\")\n",
    "print(f\"Cohen's Kappa for Qwen: {kappa_qwen:.4f}\")\n",
    "print(f\"Spearman's correlation for Mistral: {spearman_mistral:.4f}\")\n",
    "print(f\"Spearman's correlation for Deepseek: {spearman_deepseek:.4f}\")\n",
    "print(f\"Spearman's correlation for Qwen: {spearman_qwen:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cf27169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:35:26.881228Z",
     "iopub.status.busy": "2025-06-20T18:35:26.880982Z",
     "iopub.status.idle": "2025-06-20T18:35:26.886729Z",
     "shell.execute_reply": "2025-06-20T18:35:26.886057Z",
     "shell.execute_reply.started": "2025-06-20T18:35:26.881211Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Mistral: 2.5500\n",
      "Mean Squared Error for Deepseek: 1.5500\n",
      "Mean Squared Error for Qwen: 1.6000\n"
     ]
    }
   ],
   "source": [
    "# calculate the MSE for mistral and deepseek\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_mistral = mean_squared_error(manual_scores_m, mistral_scores)\n",
    "mse_deepseek = mean_squared_error(manual_scores_d, deepseek_scores)\n",
    "mse_qwen = mean_squared_error(manual_scores_q, qwen_scores)\n",
    "print(f\"Mean Squared Error for Mistral: {mse_mistral:.4f}\")\n",
    "print(f\"Mean Squared Error for Deepseek: {mse_deepseek:.4f}\")\n",
    "print(f\"Mean Squared Error for Qwen: {mse_qwen:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6329fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Scores vs Mistral Scores:\n",
      "Manual Score: 2, Mistral Score: 4\n",
      "Manual Score: 3, Mistral Score: 3\n",
      "Manual Score: 3, Mistral Score: 3\n",
      "Manual Score: 1, Mistral Score: 4\n",
      "Manual Score: 3, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 2\n",
      "Manual Score: 3, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 2\n",
      "Manual Score: 2, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 2\n",
      "Manual Score: 4, Mistral Score: 3\n",
      "Manual Score: 1, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 3\n",
      "Manual Score: 1, Mistral Score: 4\n",
      "Manual Score: 3, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 3\n",
      "Manual Score: 2, Mistral Score: 4\n",
      "Average Mistral Score: 3.0500\n",
      "Average manual Score: 2.2000\n"
     ]
    }
   ],
   "source": [
    "# print all the scores for all the models with the manual scores\n",
    "print(\"Manual Scores vs Mistral Scores:\")\n",
    "sum_judge = 0\n",
    "sum_manual = 0\n",
    "for i in range(len(manual_scores_m)):\n",
    "    sum_judge += mistral_scores[i]\n",
    "    sum_manual += manual_scores_m[i]\n",
    "    print(f\"Manual Score: {manual_scores_m[i]}, Mistral Score: {mistral_scores[i]}\")\n",
    "# print the average score for mistral\n",
    "print(f\"Average Mistral Score: {sum_judge/len(manual_scores_m):.4f}\")\n",
    "print(f\"Average manual Score: {sum_manual/len(manual_scores_m):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20845e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------- \n",
      "Manual Scores vs Deepseek Scores:\n",
      "Manual Score: 4, Deepseek Score: 3\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 2, Deepseek Score: 3\n",
      "Manual Score: 2, Deepseek Score: 2\n",
      "Manual Score: 2, Deepseek Score: 3\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 1, Deepseek Score: 1\n",
      "Manual Score: 4, Deepseek Score: 3\n",
      "Manual Score: 2, Deepseek Score: 4\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 3, Deepseek Score: 4\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 2, Deepseek Score: 3\n",
      "Manual Score: 1, Deepseek Score: 1\n",
      "Manual Score: 3, Deepseek Score: 4\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 3, Deepseek Score: 3\n",
      "Manual Score: 4, Deepseek Score: 3\n",
      "Average Deepseek Score: 2.9000\n",
      "Average manual Score: 2.7000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n -------- \\nManual Scores vs Deepseek Scores:\")\n",
    "sum_judge = 0\n",
    "sum_manual = 0\n",
    "for i in range(len(manual_scores_d)):\n",
    "    sum_judge += deepseek_scores[i]\n",
    "    sum_manual += manual_scores_d[i]\n",
    "    print(f\"Manual Score: {manual_scores_d[i]}, Deepseek Score: {deepseek_scores[i]}\")\n",
    "print(f\"Average Deepseek Score: {sum_judge/len(manual_scores_d):.4f}\")\n",
    "print(f\"Average manual Score: {sum_manual/len(manual_scores_d):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69d6e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " ------- \n",
      "Manual Scores vs Qwen Scores:\n",
      "Manual Score: 4, Qwen Score: 4\n",
      "Manual Score: 3, Qwen Score: 4\n",
      "Manual Score: 4, Qwen Score: 4\n",
      "Manual Score: 3, Qwen Score: 3\n",
      "Manual Score: 4, Qwen Score: 3\n",
      "Manual Score: 4, Qwen Score: 4\n",
      "Manual Score: 4, Qwen Score: 2\n",
      "Manual Score: 5, Qwen Score: 3\n",
      "Manual Score: 2, Qwen Score: 4\n",
      "Manual Score: 3, Qwen Score: 3\n",
      "Manual Score: 4, Qwen Score: 3\n",
      "Manual Score: 3, Qwen Score: 3\n",
      "Manual Score: 5, Qwen Score: 3\n",
      "Manual Score: 3, Qwen Score: 3\n",
      "Manual Score: 3, Qwen Score: 3\n",
      "Manual Score: 2, Qwen Score: 4\n",
      "Manual Score: 4, Qwen Score: 4\n",
      "Manual Score: 3, Qwen Score: 5\n",
      "Manual Score: 5, Qwen Score: 3\n",
      "Manual Score: 3, Qwen Score: 4\n",
      "Average Qwen Score: 3.4500\n",
      "Average manual Score: 3.5500\n"
     ]
    }
   ],
   "source": [
    "print(\" \\n ------- \\nManual Scores vs Qwen Scores:\")\n",
    "sum_judge = 0\n",
    "sum_manual = 0\n",
    "for i in range(len(manual_scores_q)):\n",
    "    sum_judge += qwen_scores[i]\n",
    "    sum_manual += manual_scores_q[i]\n",
    "    print(f\"Manual Score: {manual_scores_q[i]}, Qwen Score: {qwen_scores[i]}\")\n",
    "print(f\"Average Qwen Score: {sum_judge/len(manual_scores_q):.4f}\")\n",
    "print(f\"Average manual Score: {sum_manual/len(manual_scores_q):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ec2f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mistral",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p_mistral_vote",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0faef760-e954-45a9-9ca5-b3ff6d3c8029",
       "rows": [
        [
         "count",
         "0.0",
         "97.0"
        ],
        [
         "mean",
         null,
         "3.1752577319587627"
        ],
        [
         "std",
         null,
         "0.6456635681986163"
        ],
        [
         "min",
         null,
         "2.0"
        ],
        [
         "25%",
         null,
         "3.0"
        ],
        [
         "50%",
         null,
         "3.0"
        ],
        [
         "75%",
         null,
         "4.0"
        ],
        [
         "max",
         null,
         "4.0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mistral</th>\n",
       "      <th>p_mistral_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.175258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mistral  p_mistral_vote\n",
       "count      0.0       97.000000\n",
       "mean       NaN        3.175258\n",
       "std        NaN        0.645664\n",
       "min        NaN        2.000000\n",
       "25%        NaN        3.000000\n",
       "50%        NaN        3.000000\n",
       "75%        NaN        4.000000\n",
       "max        NaN        4.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c1a23d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "p_deepseek_vote",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3a83e68e-214b-4e70-affb-2c80d84ffa51",
       "rows": [
        [
         "count",
         "97.0"
        ],
        [
         "mean",
         "3.2268041237113403"
        ],
        [
         "std",
         "0.7145096605244872"
        ],
        [
         "min",
         "1.0"
        ],
        [
         "25%",
         "3.0"
        ],
        [
         "50%",
         "3.0"
        ],
        [
         "75%",
         "4.0"
        ],
        [
         "max",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_deepseek_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.226804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.714510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_deepseek_vote\n",
       "count        97.000000\n",
       "mean          3.226804\n",
       "std           0.714510\n",
       "min           1.000000\n",
       "25%           3.000000\n",
       "50%           3.000000\n",
       "75%           4.000000\n",
       "max           4.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepseek.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa6fa883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "p_qwen_vote",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "e7fd56ca-2223-4d1e-9b9d-08aa4e9adbc9",
       "rows": [
        [
         "count",
         "97.0"
        ],
        [
         "mean",
         "3.3917525773195876"
        ],
        [
         "std",
         "0.8845514521369932"
        ],
        [
         "min",
         "1.0"
        ],
        [
         "25%",
         "3.0"
        ],
        [
         "50%",
         "3.0"
        ],
        [
         "75%",
         "4.0"
        ],
        [
         "max",
         "5.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_qwen_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.391753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.884551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_qwen_vote\n",
       "count    97.000000\n",
       "mean      3.391753\n",
       "std       0.884551\n",
       "min       1.000000\n",
       "25%       3.000000\n",
       "50%       3.000000\n",
       "75%       4.000000\n",
       "max       5.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen.describe()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12780810,
     "datasetId": 7655949,
     "sourceId": 12235457,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 12700163,
     "datasetId": 7655934,
     "sourceId": 12164255,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 12701373,
     "datasetId": 7661970,
     "sourceId": 12165363,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
